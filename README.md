# ğŸ›¡ï¸ LogicGuard
### *Deterministic Hallucination Interception in Large Language Models Using Aristotelian-Avicennian Syllogistic Frameworks*

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/Ollama-Multi--Model-black?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/NetworkX-Graph%20Engine-orange?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/IEEE-Under%20Review-blue?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Precision-100%25-brightgreen?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge"/>
</p>

<p align="center">
  <a href="https://doi.org/10.5281/zenodo.18745460">
    <img src="https://zenodo.org/badge/DOI/10.5281/zenodo.18745460.svg" alt="DOI"/>
  </a>
  &nbsp;
  <a href="https://github.com/HamzaNasiem/LogicGuard">
    <img src="https://img.shields.io/badge/GitHub-LogicGuard-181717?style=flat&logo=github"/>
  </a>
</p>

<p align="center">
  <i>"Probabilistic AI guesses. LogicGuard formally proves."</i>
</p>

---

## What Is This?

Large Language Models are powerful semantic engines â€” but they are fundamentally unreliable deductive reasoners. Operating on token probabilities, they confidently produce logically impossible outputs:

- *"Not all squares are rectangles"* â€” logically impossible by Euclidean definition
- *"Fish have hair"* â€” structurally false by taxonomic classification
- *"Spiders are insects"* â€” a cross-branch error that any KB can definitively refute

In 2023, Google's Bard AI hallucinated one claim during a live demonstration and erased **$100 billion** in market capitalization the same day.

**LogicGuard** is a hybrid neuro-symbolic middleware that sits between LLMs and users. It computationally implements the 1,000-year-old syllogistic framework (*Qiyas / Mantiq*) of Ibn Sina (Avicenna), building a deterministic interceptor that catches and corrects structural hallucinations before they reach the user.

The core architectural insight: **parsing is probabilistic; reasoning must be deterministic.**

---

## Key Results

Evaluated on a **175-query formal syllogism dataset** â€” spanning biological taxonomy, geometric relations, and physical conditionals â€” using three open-weight LLMs running locally via Ollama:

### Accuracy Improvement

| Model | Baseline | +LogicGuard | Î” |
|-------|----------|-------------|---|
| LLaMA2-7B | 60.0% | **94.3%** | +34.3 pp |
| Mistral-7B | 94.9% | **97.7%** | +2.8 pp |
| LLaMA3.2-3B | 84.6% | **96.6%** | +12.0 pp |

### Precision / Recall / F1

| Model | Precision | Recall | F1 | Spec. | FP |
|-------|-----------|--------|----|-------|----|
| LLaMA2-7B +LG | **100%** | 90.9% | 95.2% | **100%** | **0** |
| Mistral-7B +LG | **100%** | 96.4% | 98.1% | **100%** | **0** |
| LLaMA3.2-3B +LG | **100%** | 94.5% | 97.2% | **100%** | **0** |

**Precision = 100% and FP = 0 across 525 total evaluations (175 queries Ã— 3 models).**

### Hallucination Interception

| Model | LLM Errors | Intercepted | Rate |
|-------|-----------|-------------|------|
| LLaMA2-7B | 70 | 62 | **88.6%** |
| Mistral-7B | 9 | 9 | **100.0%** |
| LLaMA3.2-3B | 27 | 25 | **92.6%** |

### Out-of-Domain Generalization

Applied to the full **TruthfulQA benchmark** (790 general-knowledge questions) without any LLM calls:

- **99.5% non-interference rate** â€” LogicGuard correctly deferred to the LLM on 786/790 questions
- Only 4 questions (0.5%) matched KB patterns â€” proving zero KB-test co-derivation

---

## Architecture

LogicGuard is a **two-stage neuro-symbolic pipeline**:

```
User Question (natural language)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: Neural Semantic Parser â”‚  â† LLM constrained to JSON-only output
â”‚                                  â”‚    Temperature=0. Never answers.
â”‚  {"type": "taxonomic",           â”‚    Falls back to regex if Ollama offline.
â”‚   "subject": "dog",              â”‚
â”‚   "predicate": "mammal"}         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚  Structured JSON proposition
                 â–¼  (no logical content trusted)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: BFS Graph Validator    â”‚  â† 100% deterministic. No probability.
â”‚                                  â”‚    NetworkX directed semantic graph.
â”‚  dog â†’ canine â†’ mammal â†’ âœ“      â”‚    115 nodes, 136 IS-A edges.
â”‚  graph answer: TRUE              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        YAQEEN / WAHM / ZANN / SHAKK
```

### The Key Contribution

The LLM in Stage 1 is **caged**: it can only output one of four JSON schemas. It never answers the question. All actual logical reasoning happens in Stage 2, which is pure graph traversal with mathematical guarantees.

If the query falls outside the KB (Shakk state), LogicGuard **does not intervene** â€” it defers to the LLM. This deliberate pass-through is why Precision stays at 100%: the system never overclaims certainty on queries it cannot formally adjudicate.

---

## Three Forms of Ibn Sina's Qiyas (Syllogism)

### 1. Qiyas al-Haml â€” Taxonomic (IS-A)
```
"Are all dogs mammals?"
â†’ JSON:  {"type": "taxonomic", "subject": "dog", "predicate": "mammal"}
â†’ BFS:   dog â†’ canine â†’ mammal âœ“ (path found)
â†’ State: YAQEEN (Certainty â€” override LLM if wrong)

"Are all animals dogs?"
â†’ BFS:   No path from animal â†’ dog âœ—
â†’ State: WAHM (Illusion â€” intercept LLM hallucination)
```

### 2. Qiyas al-Istithna â€” Hypothetical (Modus Ponens)
```
"If water freezes, does it become ice?"
â†’ JSON:  {"type": "hypothetical", "condition": "water freezes", "consequence": "ice"}
â†’ Check: water_freezes â†’ ice âˆˆ G_C âœ“
â†’ State: YAQEEN
```

### 3. Categorical â€” Property Inheritance
```
"Do all birds have feathers?"
â†’ JSON:  {"type": "categorical", "entity": "bird", "property": "feathers"}
â†’ Check: bird â†’ feathers âˆˆ G_P âœ“ (direct or inherited)
â†’ State: YAQEEN

"Do all fish have hair?"
â†’ Check: fish âŠ¬ hair âœ—
â†’ State: WAHM
```

---

## Epistemic State Classification

LogicGuard replaces binary True/False with Ibn Sina's four-state epistemic framework:

| State | Meaning | When | Action |
|-------|---------|------|--------|
| **Yaqeen** ğŸŸ¢ | Certainty | BFS path confirmed in KB | Override LLM with validated answer |
| **Zann** ğŸŸ¡ | Probability | Semantic match; no formal structure | Return LLM answer with confidence flag |
| **Shakk** ğŸŸ  | Doubt | Entity absent from KB scope | Defer to LLM â€” no intervention |
| **Wahm** ğŸ”´ | Illusion | LLM answer contradicts BFS result | Intercept and flag structural hallucination |

The **Shakk** state is the precision guarantee: when LogicGuard is uncertain, it says so and defers. It never invents certainty it does not have.

---

## Installation

### Prerequisites
- Python 3.8+
- [Ollama](https://ollama.ai/) installed locally

```bash
# Install models (choose what you want to evaluate)
ollama pull llama2          # 7B â€” higher error rate baseline
ollama pull mistral         # 7B â€” strong mid-range baseline
ollama pull llama3.2:3b     # 3B â€” compact edge model

# Clone
git clone https://github.com/HamzaNasiem/LogicGuard.git
cd LogicGuard

# Install dependencies
pip install networkx pandas numpy matplotlib ollama scikit-learn
```

---

## Usage

### Full Pipeline (Steps 1â€“5)
```bash
# Requires ProofWriter dataset (download separately â€” not in repo)
python run_all.py --proofwriter_dir path/to/proofwriter-dataset-V2020.12.3

# Steps only (if KB and queries already built)
python run_all.py --steps 2,3
python run_all.py --steps 4,5   # TruthfulQA + paper tables
```

### Step-by-Step

```bash
# Step 1: Build Knowledge Base from ProofWriter
python step1_proofwriter_extractor.py --proofwriter_dir ./proofwriter-dataset-V2020.12.3

# Step 2: Run multi-model evaluation (requires Ollama + models)
python step2_multi_model_runner.py

# Step 3: Compute metrics (Precision/Recall/F1, confusion matrices)
python step3_metrics.py

# Step 4: TruthfulQA generalization test (no LLM needed â€” fast)
python step4_truthfulqa_validation.py --csv truthfulqa.csv --kb knowledge_base_extended.json

# Step 5: Generate all IEEE paper tables and text
python step5_generate_paper_tables.py
```

### Use as a Library

```python
from step2_multi_model_runner import LogicGuardValidator
import json

with open("knowledge_base_extended.json") as f:
    kb = json.load(f)

validator = LogicGuardValidator(kb)
result = validator.validate("Are all squares rectangles?", "taxonomic")

print(result["epistemic_state"])   # YAQEEN
print(result["graph_answer"])      # True
print(result["covered"])           # True
```

---

## Repository Structure

```
LogicGuard/
â”‚
â”œâ”€â”€ step1_proofwriter_extractor.py  # ProofWriter â†’ KB builder
â”œâ”€â”€ step2_multi_model_runner.py     # Multi-model evaluation engine
â”œâ”€â”€ step3_metrics.py                # P/R/F1, confusion matrices, reports
â”œâ”€â”€ step4_truthfulqa_validation.py  # Out-of-domain generalization test
â”œâ”€â”€ step5_generate_paper_tables.py  # IEEE paper tables
â”œâ”€â”€ run_all.py                      # Master pipeline runner (Steps 1â€“5)
â”œâ”€â”€ knowledge_base.json             # Base KB (hand-curated)
â””â”€â”€ knowledge_base_extended.json    # KB after ProofWriter extension
```

---

## Knowledge Base

Three interconnected directed graphs built on top of ProofWriter triples:

```python
# Taxonomy (IS-A hierarchy) â€” 115 nodes, 136 edges
dog â†’ canine â†’ mammal â†’ animal â†’ living_thing
square â†’ rectangle â†’ quadrilateral â†’ polygon â†’ shape
spider â†’ arachnid â†’ invertebrate â†’ animal â†’ living_thing

# Property (with transitive inheritance) â€” 115 associations
mammal   â†’ {hair, warm_blood, backbone, gives_milk, ...}
bird     â†’ {feathers, wings, beak, lay_eggs, ...}
reptile  â†’ {scales, cold_blood, ...}
insect   â†’ {six_legs, exoskeleton, ...}
arachnid â†’ {eight_legs, ...}

# Conditional (Modus Ponens rules) â€” 49 rules
raining          â†’ {ground_wet, wet}
water_freezes    â†’ {ice, solid, becomes_ice}
fire_present     â†’ {heat, smoke, oxygen_consumed}
metal_heated     â†’ {expands}
```

---

## Why Precision = 100% Is Not a Suspicious Claim

For a probabilistic system, 100% precision on any non-trivial dataset would rightly invite scrutiny. LogicGuard's Stage 2 is not probabilistic.

A false positive requires the BFS algorithm to erroneously determine that an IS-A path does not exist when it does. **This is computationally impossible given a correct KB.** BFS either finds a path or it doesn't, and its answer is verified by the graph structure itself.

What *is* empirical â€” and where real uncertainty resides â€” is the Recall figure (90.9â€“96.4%), which reflects genuine KB coverage gaps. These are reported honestly.

The formal scope: **Precision = 100% within KB-covered queries.** The system explicitly returns Shakk and defers on queries outside this scope. The 99.5% non-interference rate on TruthfulQA demonstrates this scope is conservatively applied.

---

## Reproducibility

All experiments run locally on commodity hardware (CPU-only), no GPU required:

```bash
# Fixed seed for full reproducibility
# All Ollama calls: temperature=0.0, seed=42

python run_all.py --proofwriter_dir proofwriter-dataset-V2020.12.3
# Runtime: ~44 minutes (all 3 models, 175 queries Ã— 2 configs each)
```

---

## Citation

If you use LogicGuard in your research, please cite both the paper and the code:

**Paper (Zenodo preprint):**
```bibtex
@misc{naseem2026logicguard,
  author    = {Naseem, Hamza and Ali, Moiz},
  title     = {LogicGuard: A Neuro-Symbolic Middleware for Deterministic
               Hallucination Interception in Large Language Models
               Using Aristotelian-Avicennian Syllogistic Frameworks},
  year      = {2026},
  publisher = {Zenodo},
  doi       = {10.5281/zenodo.18745460},
  url       = {https://doi.org/10.5281/zenodo.18745460}
}
```

---

## Future Work

- **ConceptNet / Wikidata integration** â€” Replace the manually curated KB with 8M+ semantic relationships via public APIs
- **Legal and medical domains** â€” Statutes as conditionals, symptom-disease mappings
- **Fine-tuned Stage 1 parser** â€” BERT-based sequence classifier to eliminate LLM dependency in parsing
- **Multi-hop conditionals** â€” Explicit chaining semantics for nested IF-THEN inference
- **Real-time API** â€” FastAPI wrapper for enterprise hallucination guardrail deployment

---

## Contributing

Open an issue before submitting major changes. Pull requests welcome for:
- KB extensions (new taxonomies, properties, conditionals)
- New query types or evaluation domains
- Stage 1 parser improvements

---

<p align="center">
  Built on classical logic and modern AI.<br>
  <i>Ibn Sina (980â€“1037 CE) formalized deductive logic. We made it intercept LLM hallucinations.</i><br><br>
  <a href="https://doi.org/10.5281/zenodo.18745460">ğŸ“„ Read the Paper</a> &nbsp;Â·&nbsp;
  <a href="https://github.com/HamzaNasiem/LogicGuard">ğŸ’» View Code</a>
</p>