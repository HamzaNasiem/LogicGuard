{
  "metrics": {
    "llama2_7b_baseline": {
      "overall": {
        "precision": 97.6,
        "recall": 37.3,
        "f1": 53.9,
        "accuracy": 60.0,
        "specificity": 98.5
      },
      "per_type": {
        "taxonomic": {
          "n": 85,
          "cm": {
            "TP": 9,
            "TN": 30,
            "FP": 0,
            "FN": 46,
            "total": 85
          },
          "metrics": {
            "precision": 100.0,
            "recall": 16.4,
            "f1": 28.1,
            "accuracy": 45.9,
            "specificity": 100.0
          }
        },
        "categorical": {
          "n": 60,
          "cm": {
            "TP": 14,
            "TN": 25,
            "FP": 0,
            "FN": 21,
            "total": 60
          },
          "metrics": {
            "precision": 100.0,
            "recall": 40.0,
            "f1": 57.1,
            "accuracy": 65.0,
            "specificity": 100.0
          }
        },
        "hypothetical": {
          "n": 30,
          "cm": {
            "TP": 18,
            "TN": 9,
            "FP": 1,
            "FN": 2,
            "total": 30
          },
          "metrics": {
            "precision": 94.7,
            "recall": 90.0,
            "f1": 92.3,
            "accuracy": 90.0,
            "specificity": 90.0
          }
        }
      }
    },
    "llama2_7b_logicguard": {
      "overall": {
        "precision": 100.0,
        "recall": 90.9,
        "f1": 95.2,
        "accuracy": 94.3,
        "specificity": 100.0
      },
      "per_type": {
        "taxonomic": {
          "n": 85,
          "cm": {
            "TP": 54,
            "TN": 30,
            "FP": 0,
            "FN": 1,
            "total": 85
          },
          "metrics": {
            "precision": 100.0,
            "recall": 98.2,
            "f1": 99.1,
            "accuracy": 98.8,
            "specificity": 100.0
          }
        },
        "categorical": {
          "n": 60,
          "cm": {
            "TP": 27,
            "TN": 25,
            "FP": 0,
            "FN": 8,
            "total": 60
          },
          "metrics": {
            "precision": 100.0,
            "recall": 77.1,
            "f1": 87.1,
            "accuracy": 86.7,
            "specificity": 100.0
          }
        },
        "hypothetical": {
          "n": 30,
          "cm": {
            "TP": 19,
            "TN": 10,
            "FP": 0,
            "FN": 1,
            "total": 30
          },
          "metrics": {
            "precision": 100.0,
            "recall": 95.0,
            "f1": 97.4,
            "accuracy": 96.7,
            "specificity": 100.0
          }
        }
      }
    },
    "mistral_7b_baseline": {
      "overall": {
        "precision": 95.5,
        "recall": 96.4,
        "f1": 95.9,
        "accuracy": 94.9,
        "specificity": 92.3
      },
      "per_type": {
        "taxonomic": {
          "n": 85,
          "cm": {
            "TP": 53,
            "TN": 29,
            "FP": 1,
            "FN": 2,
            "total": 85
          },
          "metrics": {
            "precision": 98.1,
            "recall": 96.4,
            "f1": 97.2,
            "accuracy": 96.5,
            "specificity": 96.7
          }
        },
        "categorical": {
          "n": 60,
          "cm": {
            "TP": 34,
            "TN": 22,
            "FP": 3,
            "FN": 1,
            "total": 60
          },
          "metrics": {
            "precision": 91.9,
            "recall": 97.1,
            "f1": 94.4,
            "accuracy": 93.3,
            "specificity": 88.0
          }
        },
        "hypothetical": {
          "n": 30,
          "cm": {
            "TP": 19,
            "TN": 9,
            "FP": 1,
            "FN": 1,
            "total": 30
          },
          "metrics": {
            "precision": 95.0,
            "recall": 95.0,
            "f1": 95.0,
            "accuracy": 93.3,
            "specificity": 90.0
          }
        }
      }
    },
    "mistral_7b_logicguard": {
      "overall": {
        "precision": 100.0,
        "recall": 96.4,
        "f1": 98.1,
        "accuracy": 97.7,
        "specificity": 100.0
      },
      "per_type": {
        "taxonomic": {
          "n": 85,
          "cm": {
            "TP": 55,
            "TN": 30,
            "FP": 0,
            "FN": 0,
            "total": 85
          },
          "metrics": {
            "precision": 100.0,
            "recall": 100.0,
            "f1": 100.0,
            "accuracy": 100.0,
            "specificity": 100.0
          }
        },
        "categorical": {
          "n": 60,
          "cm": {
            "TP": 32,
            "TN": 25,
            "FP": 0,
            "FN": 3,
            "total": 60
          },
          "metrics": {
            "precision": 100.0,
            "recall": 91.4,
            "f1": 95.5,
            "accuracy": 95.0,
            "specificity": 100.0
          }
        },
        "hypothetical": {
          "n": 30,
          "cm": {
            "TP": 19,
            "TN": 10,
            "FP": 0,
            "FN": 1,
            "total": 30
          },
          "metrics": {
            "precision": 100.0,
            "recall": 95.0,
            "f1": 97.4,
            "accuracy": 96.7,
            "specificity": 100.0
          }
        }
      }
    },
    "llama32_3b_baseline": {
      "overall": {
        "precision": 97.7,
        "recall": 77.3,
        "f1": 86.3,
        "accuracy": 84.6,
        "specificity": 96.9
      },
      "per_type": {
        "taxonomic": {
          "n": 85,
          "cm": {
            "TP": 48,
            "TN": 30,
            "FP": 0,
            "FN": 7,
            "total": 85
          },
          "metrics": {
            "precision": 100.0,
            "recall": 87.3,
            "f1": 93.2,
            "accuracy": 91.8,
            "specificity": 100.0
          }
        },
        "categorical": {
          "n": 60,
          "cm": {
            "TP": 18,
            "TN": 24,
            "FP": 1,
            "FN": 17,
            "total": 60
          },
          "metrics": {
            "precision": 94.7,
            "recall": 51.4,
            "f1": 66.7,
            "accuracy": 70.0,
            "specificity": 96.0
          }
        },
        "hypothetical": {
          "n": 30,
          "cm": {
            "TP": 19,
            "TN": 9,
            "FP": 1,
            "FN": 1,
            "total": 30
          },
          "metrics": {
            "precision": 95.0,
            "recall": 95.0,
            "f1": 95.0,
            "accuracy": 93.3,
            "specificity": 90.0
          }
        }
      }
    },
    "llama32_3b_logicguard": {
      "overall": {
        "precision": 100.0,
        "recall": 94.5,
        "f1": 97.2,
        "accuracy": 96.6,
        "specificity": 100.0
      },
      "per_type": {
        "taxonomic": {
          "n": 85,
          "cm": {
            "TP": 55,
            "TN": 30,
            "FP": 0,
            "FN": 0,
            "total": 85
          },
          "metrics": {
            "precision": 100.0,
            "recall": 100.0,
            "f1": 100.0,
            "accuracy": 100.0,
            "specificity": 100.0
          }
        },
        "categorical": {
          "n": 60,
          "cm": {
            "TP": 30,
            "TN": 25,
            "FP": 0,
            "FN": 5,
            "total": 60
          },
          "metrics": {
            "precision": 100.0,
            "recall": 85.7,
            "f1": 92.3,
            "accuracy": 91.7,
            "specificity": 100.0
          }
        },
        "hypothetical": {
          "n": 30,
          "cm": {
            "TP": 19,
            "TN": 10,
            "FP": 0,
            "FN": 1,
            "total": 30
          },
          "metrics": {
            "precision": 100.0,
            "recall": 95.0,
            "f1": 97.4,
            "accuracy": 96.7,
            "specificity": 100.0
          }
        }
      }
    }
  },
  "confusion_matrices": {
    "llama2_7b_baseline": {
      "TP": 41,
      "TN": 64,
      "FP": 1,
      "FN": 69,
      "total": 175
    },
    "llama2_7b_logicguard": {
      "TP": 100,
      "TN": 65,
      "FP": 0,
      "FN": 10,
      "total": 175
    },
    "mistral_7b_baseline": {
      "TP": 106,
      "TN": 60,
      "FP": 5,
      "FN": 4,
      "total": 175
    },
    "mistral_7b_logicguard": {
      "TP": 106,
      "TN": 65,
      "FP": 0,
      "FN": 4,
      "total": 175
    },
    "llama32_3b_baseline": {
      "TP": 85,
      "TN": 63,
      "FP": 2,
      "FN": 25,
      "total": 175
    },
    "llama32_3b_logicguard": {
      "TP": 104,
      "TN": 65,
      "FP": 0,
      "FN": 6,
      "total": 175
    }
  },
  "hallucination_analysis": {
    "llama2_7b": {
      "intercepted": 62,
      "intercepted_qs": [
        "Are all lions mammals?",
        "Are all tigers felines?",
        "Are all wolves canines?",
        "Are all sharks fish?",
        "Are all salmon fish?",
        "Are all eagles birds?",
        "Are all sparrows birds?",
        "Are all snakes reptiles?",
        "Are all lizards reptiles?",
        "Are all frogs amphibians?",
        "Are all penguins birds?",
        "Are all squares rectangles?",
        "Are all rectangles polygons?",
        "Are all triangles polygons?",
        "Are all cars vehicles?",
        "Are all bicycles vehicles?",
        "Are all birds animals?",
        "Are all mammals animals?",
        "Are all airplanes vehicles?",
        "Are all boats vehicles?",
        "Are all penguins animals?",
        "Do all mammals have hair?",
        "Do all birds have wings?",
        "Do all fish have gills?",
        "Do all rectangles have four sides?",
        "Do all reptiles have scales?",
        "Do all triangles have three sides?",
        "Do all insects have six legs?",
        "Do all spiders have eight legs?",
        "If metal is heated, does it expand?",
        "If a person is human, are they mortal?",
        "Are all foxes canines?",
        "Are all leopards felines?",
        "Are all turtles reptiles?",
        "Are all crocodiles reptiles?",
        "Are all toads amphibians?",
        "Are all ants insects?",
        "Are all bees insects?",
        "Are all spiders arachnids?",
        "Are all hexagons polygons?",
        "Are all pentagons polygons?",
        "Are all rhombuses quadrilaterals?",
        "Are all airplanes aircraft?",
        "Are all helicopters aircraft?",
        "Are all buses vehicles?",
        "Are all trains vehicles?",
        "Are all apples fruits?",
        "Are all bananas fruits?",
        "Are all carrots vegetables?",
        "Are all trees plants?",
        "Are all flowers plants?",
        "Are all insects animals?",
        "Are all reptiles animals?",
        "Are all fish animals?",
        "Are all amphibians animals?",
        "Do all fish have scales?",
        "Do all arachnids have eight legs?",
        "Do all squares have equal sides?",
        "Do all squares have right angles?",
        "Do all circles have a radius?",
        "Do all aircraft have wings?",
        "If fire is present, does temperature drop?"
      ],
      "false_alarms": 2,
      "false_alarm_qs": [
        "If it is raining, do we need an umbrella?",
        "Do all mammals have warm blood?"
      ],
      "both_correct": 103,
      "both_wrong": 8,
      "total_llm_errors": 70,
      "interception_rate": 88.6
    },
    "mistral_7b": {
      "intercepted": 9,
      "intercepted_qs": [
        "Are all squares rectangles?",
        "Are all dolphins fish?",
        "Do all insects have six legs?",
        "Do all squares have three sides?",
        "If fire is present, is oxygen consumed?",
        "Are all foxes canines?",
        "Do all insects have eight legs?",
        "Do all arachnids have six legs?",
        "If metal is heated, does it shrink?"
      ],
      "false_alarms": 4,
      "false_alarm_qs": [
        "Do all circles have a curved edge?",
        "If it is raining, do we need an umbrella?",
        "Do all mammals have warm blood?",
        "Do all reptiles have cold blood?"
      ],
      "both_correct": 162,
      "both_wrong": 0,
      "total_llm_errors": 9,
      "interception_rate": 100.0
    },
    "llama32_3b": {
      "intercepted": 25,
      "intercepted_qs": [
        "Are all dolphins mammals?",
        "Are all sharks fish?",
        "Are all salmon fish?",
        "Are all squares rectangles?",
        "Are all boats vehicles?",
        "Do all mammals have hair?",
        "Do all birds have feathers?",
        "Do all birds have wings?",
        "Do all fish have gills?",
        "Do all mammals have a backbone?",
        "Do all reptiles have scales?",
        "Do all insects have six legs?",
        "Do all spiders have eight legs?",
        "Are all foxes canines?",
        "Are all carrots vegetables?",
        "Do all birds have a beak?",
        "Do all fish have scales?",
        "Do all arachnids have eight legs?",
        "Do all squares have equal sides?",
        "Do all squares have right angles?",
        "Do all trees have roots?",
        "Do all aircraft have wings?",
        "Do all arachnids have six legs?",
        "If electricity flows, is the circuit complete?",
        "If metal is heated, does it shrink?"
      ],
      "false_alarms": 4,
      "false_alarm_qs": [
        "Do all circles have a curved edge?",
        "If it is raining, do we need an umbrella?",
        "Do all mammals have warm blood?",
        "Do all reptiles have cold blood?"
      ],
      "both_correct": 144,
      "both_wrong": 2,
      "total_llm_errors": 27,
      "interception_rate": 92.6
    }
  }
}